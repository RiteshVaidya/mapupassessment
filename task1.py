# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/RiteshVaidya/mapupassessment/blob/main/task1.ipynb
"""

import pandas as pd

def generate_car_matrix(dataset1_path: str) -> pd.DataFrame:
    """
    Creates a DataFrame for id combinations from dataset-1.csv.

    Args:
        dataset1_path (str): Path to dataset-1.csv.

    Returns:
        pandas.DataFrame: Matrix generated with 'car' values,
                          where 'id_1' and 'id_2' are used as indices and columns respectively.
    """
    # Read dataset-1.csv
    df = pd.read_csv(dataset1_path)

    # Use pivot_table to handle duplicate entries
    car_matrix = df.pivot_table(index='id_1', columns='id_2', values='car', aggfunc='sum', fill_value=0)

    return car_matrix


dataset1_path = 'dataset-1.csv'
result_matrix = generate_car_matrix(dataset1_path)
print(result_matrix)


#2

import pandas as pd


dataset1_df = pd.read_csv('dataset-1.csv')

def get_type_count(df: pd.DataFrame) -> dict:
    """
    Categorizes 'car' values into types and returns a dictionary of counts.

    Args:
        df (pandas.DataFrame)

    Returns:
        dict: A dictionary with car types as keys and their counts as values.
    """
    # Extract unique car types and count their occurrences
    car_counts = df['car'].value_counts().to_dict()

    return car_counts

result_type_count = get_type_count(dataset1_df)
print(result_type_count)


#3

import pandas as pd


dataset1_df = pd.read_csv('dataset-1.csv')

def get_bus_indexes(df: pd.DataFrame) -> list:
    """
    Returns the indexes where the 'bus' values are greater than twice the mean.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of indexes where 'bus' values exceed twice the mean.
    """
    # Calculate the mean of 'bus' values
    bus_mean = df['bus'].mean()

    # Get indexes where 'bus' values are greater than twice the mean
    bus_indexes = df[df['bus'] > 2 * bus_mean].index.tolist()

    return bus_indexes
:
result_bus_indexes = get_bus_indexes(dataset1_df)
print(result_bus_indexes)


#4

import pandas as pd

def filter_routes(df: pd.DataFrame) -> list:
    """
    Filters and returns routes with average 'truck' values greater than 7.

    Args:
        df (pandas.DataFrame)

    Returns:
        list: List of route names with average 'truck' values greater than 7.
    """
    # Calculate the mean 'truck' values for each route
    route_avg_truck = df.groupby('route')['truck'].mean()

    # Filter routes with average 'truck' values greater than 7
    selected_routes = route_avg_truck[route_avg_truck > 7].index.tolist()

    return selected_routes

df = pd.read_csv('dataset-1.csv')

result_routes = filter_routes(df)
print(result_routes)


#5
import pandas as pd

def multiply_matrix(matrix: pd.DataFrame) -> pd.DataFrame:
    """
    Multiplies matrix values with custom conditions.

    Args:
        matrix (pandas.DataFrame)

    Returns:
        pandas.DataFrame: Modified matrix with values multiplied based on custom conditions.
    """
    # Example custom condition: Multiply values greater than 10 by 2
    modified_matrix = matrix.applymap(lambda x: x * 2 if x > 10 else x)

    return modified_matrix

df = pd.DataFrame({
    'A': [5, 12, 8],
    'B': [15, 7, 20],
    'C': [10, 6, 14]
})

result_matrix = multiply_matrix(df)
print(result_matrix)


#6

import pandas as pd

def time_check(df: pd.DataFrame) -> pd.Series:
    """
    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period.

    Args:
        df (pandas.DataFrame)

    Returns:
        pd.Series: return a boolean series
    """
    df2 = pd.read_csv('dataset-2.csv', error_bad_lines=False)

    # Check the column names in the DataFrame from dataset-2
    print(df2.columns)


    merged_df = pd.merge(df, df2, left_on='id_2_new', right_on='id_2', how='inner')

    # Convert the timestamp columns to datetime objects
    merged_df['start_time'] = pd.to_datetime(merged_df['startDay'] + ' ' + merged_df['startTime'])
    merged_df['end_time'] = pd.to_datetime(merged_df['endDay'] + ' ' + merged_df['endTime'])

    # Calculate the time duration for each entry
    duration = merged_df['end_time'] - merged_df['start_time']

    # Check if the duration covers a full 24-hour and 7 days period
    completeness_check = (duration >= pd.Timedelta(days=7) - pd.Timedelta(seconds=1)) & (duration >= pd.Timedelta(days=1) - pd.Timedelta(seconds=1))

    return completeness_check

result_completeness = time_check(df)
print(result_completeness)












def time_check(df)->pd.Series:
    """
    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period

    Args:
        df (pandas.DataFrame)

    Returns:
        pd.Series: return a boolean series
    """
    # Write your logic here

    return pd.Series()

"""# New Section"""